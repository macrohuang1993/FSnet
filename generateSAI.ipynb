{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Generating .h5 dataset of SAI from trained ViewNet. \n",
    "### To run:\n",
    "1. Modify the network path, the SAI dataset saving path f. \n",
    "2. Check the FSdata_path , lfsize (depending on whether avoid inverse crime or not), SAI_iv, iu, nF, the network constructor is choosing right network.\n",
    "3. Whether the right transform is used, Note for avoiding iverse crime the FS has to divided by about 9000\n",
    "4. Check avoid_invCrime boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from unet_layers import *\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import FSdataset_withName,FSdataset_withName_h5,my_paired_RandomCrop,my_paired_normalize, my_paired_gamma_correction\n",
    "from visualize import show_FS,show_EPI_xu,show_EPI_yv,show_SAI\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False #Setting to True may leads to faster but undeterminsitc result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 1 # has to be one\n",
    "bs_val = 1 # has to be one\n",
    "\n",
    "avoid_invCrime = False # Change to false if not \n",
    "\n",
    "nF=7\n",
    "SAI_iv = 3 #index of the SAI to be selected as All in focus image, countin from 0 \n",
    "SAI_iu = 3 #index of the SAI to be selected as All in focus image, countin from 0\n",
    "#dimensions of Lytro light fields, H,W,nv,nu. \n",
    "#Note original Lytro LF has dimension 376X541 X 14 X 14, the paper takes only first 372/540 spatial pixel and central 8 by 8 SAI\n",
    "#which is being followed here\n",
    "if not avoid_invCrime:\n",
    "    lfsize = [372, 540, 8, 8] #H,W,v,u\n",
    "    transform_train = T.Compose([my_paired_normalize(255)])\n",
    "    transform_val = T.Compose([my_paired_normalize(255)])\n",
    "    ds_train = FSdataset_withName(lfsize = lfsize, FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_GenPy_FSview_rounding_true.h5',\\\n",
    "                              LFdata_folder='/home/zyhuang/EVO970Plus/Flowers_8bit/',trainorval='train',transform = transform_train)\n",
    "    ds_val =  FSdataset_withName(lfsize = lfsize, FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_GenPy_FSview_rounding_true.h5',\\\n",
    "                             LFdata_folder='/home/zyhuang/EVO970Plus/Flowers_8bit/',trainorval='val',transform = transform_val)\n",
    "else:\n",
    "    lfsize = [185, 269, 7, 7] #H,W,v,u\n",
    "    transform_train = T.Compose([my_paired_normalize({'FS':9000,'LF':1})]) #Since FS is not normalized in matlab and LF is normalized already to [0,1]\n",
    "    transform_val = T.Compose([my_paired_normalize({'FS':9000,'LF':1})])\n",
    "    ds_train = FSdataset_withName_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',\\\n",
    "                              LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='train',transform = transform_train)\n",
    "    ds_val =  FSdataset_withName_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',\\\n",
    "                             LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='val',transform = transform_val)\n",
    "    \n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=False, num_workers = 8,pin_memory = True)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 8,pin_memory = True)\n",
    "\n",
    "path = 'logs/Not_Avoid_invcrime/Two stage model/ViewNet/FS_dmin_-1_dmax_0.3_nF_7_GenPy_FSview_rounding_true/unet_FS2SAI_v3_tanh/lr_3e-4_bs_train_2_bs_val_5/model.pth' #Model path of view net\n",
    "f = h5py.File('SAI_dataset/FS_dmin_-1_dmax_0.3_nF_7_GenPy_FSview_rounding_true_unet_FS2SAI_v3_tanh_lr_3e-4_bs_train_2_bs_val_5.h5', 'w') #Path of saving the generated SAI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = unet_FS2SAI_v3(nF=nF,nu=lfsize[3],nv=lfsize[2],box_constraint = 'tanh')\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(path))\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "f.create_group('train')\n",
    "f.create_group('val')\n",
    "Total_loss = 0\n",
    "for idx,data_withName in enumerate(val_loader,0):\n",
    "    data,name = data_withName\n",
    "    name = name[0] # unpack name list, due to dataloader collacate fn, name is in a size 1 list.\n",
    "    FS,LF=data['FS'].to(device),data['LF'].to(device) \n",
    "    SAI = LF[:,:,SAI_iv,SAI_iu,:,:] #B,C,H,W\n",
    "    with torch.no_grad():\n",
    "        reconSAI=net(FS)\n",
    "        loss=criterion(reconSAI,SAI)\n",
    "        print(\"[%d/%d], loss is %.4f\" %(idx+1,len(val_loader),loss.item()))\n",
    "        Total_loss += loss.item()\n",
    "    f['val'].create_dataset(name,data = torch.squeeze(reconSAI).cpu().numpy())\n",
    "print(\"Mean Loss is {:.4f}\".format(Total_loss/len(val_loader)))\n",
    "Total_loss = 0\n",
    "for idx,data_withName in enumerate(train_loader,0):\n",
    "    data,name = data_withName\n",
    "    name = name[0] # unpack name list, due to dataloader collacate fn, name is in a size 1 list.\n",
    "    FS,LF=data['FS'].to(device),data['LF'].to(device) \n",
    "    SAI = LF[:,:,SAI_iv,SAI_iu,:,:] #B,C,H,W\n",
    "    with torch.no_grad():\n",
    "        reconSAI=net(FS)\n",
    "        loss=criterion(reconSAI,SAI)\n",
    "        print(\"[%d/%d], loss is %.4f\" %(idx+1,len(train_loader),loss.item()))\n",
    "        Total_loss += loss.item()\n",
    "    f['train'].create_dataset(name,data = torch.squeeze(reconSAI).cpu().numpy())\n",
    "print(\"Mean Loss is {:.4f}\".format(Total_loss/len(train_loader)))                            \n",
    "f.close()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
