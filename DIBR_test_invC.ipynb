{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test time inference of DIBR_train_invC_ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from unet_layers import *\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import FSdataset_h5,FSdataset_withSAI_h5,my_triplet_RandomCrop,my_paired_normalize,my_triplet_normalize, my_triplet_CenterCrop\n",
    "from visualize import show_FS,show_EPI_xu,show_EPI_yv,show_SAI\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from DIBR_modules import depth_rendering_pt,transform_ray_depths_pt,depth_consistency_loss_pt,image_derivs_pt,tv_loss_pt\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0,1\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False #Setting to True may leads to faster but undeterminsitc result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 1\n",
    "bs_val = 1\n",
    "lr = 3e-4\n",
    "SAI_only = False # Whether only use SAI for depth estimation (without FS)\n",
    "concat_SAI = True # whether concat SAI with FS along color channel for the depth estimation.(only matter when SAI_only = False)\n",
    "nF=7\n",
    "lfsize = [185, 269, 7, 7] #H,W,v,u\n",
    "disp_mult = 1\n",
    "SAI_iv = 3 #index of the SAI to be selected as All in focus image, countin from 0 \n",
    "SAI_iu = 3 #index of the SAI to be selected as All in focus image, countin from 0 \n",
    "lam_tv = 0.01 \n",
    "lam_dc = 0.005 # 10 times larger will ensure depth fields to be consistent, not optimal yet, try reduce to 5?\n",
    "#dimensions of Lytro light fields, H,W,nv,nu. \n",
    "#Note original Lytro LF has dimension 376X541 X 14 X 14, the paper takes only first 372/540 spatial pixel and central 8 by 8 SAI\n",
    "#which is being followed here\n",
    "\n",
    "\n",
    "FSdata_path = '/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5'\n",
    "LFdata_path = '/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5'\n",
    "if SAI_only:\n",
    "    transform_train = T.Compose([my_paired_normalize({'FS':9000,'LF':1})]) #Since FS is not normalized in matlab and LF is normalized already to [0,1]\n",
    "    transform_val = T.Compose([my_paired_normalize({'FS':9000,'LF':1})])\n",
    "    ds_train = FSdataset_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,trainorval='train',transform = transform_train)\n",
    "    ds_val =  FSdataset_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,trainorval='val',transform = transform_val) \n",
    "else:\n",
    "    SAIdata_folder = '/home/zyhuang/EVO970Plus/SAI_dataset/FS_dmin_-1_dmax_0.3_nF_7_unet_FS2SAI_v3_tanh_lr_3e-4_bs_train_2_bs_val_5_inverseCrime.h5'\n",
    "    transform_train = T.Compose([my_triplet_normalize({'FS':9000,'LF':1})])\n",
    "    transform_val = T.Compose([my_triplet_normalize({'FS':9000,'LF':1})])\n",
    "    ds_train = FSdataset_withSAI_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,SAIdata_folder = SAIdata_folder,trainorval='train',transform = transform_train)\n",
    "    ds_val =  FSdataset_withSAI_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,SAIdata_folder = SAIdata_folder,trainorval='val',transform = transform_val)\n",
    "    \n",
    "#model_folder = 'logs/Avoid_invcrime/Two stage model/DIBR/SAI_only_True_disp_mult_1_detach_ray_depths/lr_3e-4_lam_tv_1e-2_lam_dc_5e-3_bs_train_1_bs_val_1'\n",
    "model_folder = 'logs/Avoid_invcrime/Two stage model/DIBR/FS_dmin_-1_dmax_0.3_nF_7_GenMat/concat_SAI_True_disp_mult_1_detach_ray_depths/lr_3e-4_lam_tv_1e-2_lam_dc_5e-3_bs_train_1_bs_val_1'\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True, num_workers = 3,pin_memory = True)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 3,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "criterion = nn.L1Loss()\n",
    "depth_Net = depth_network_pt(nF,lfsize,disp_mult,concat_SAI = concat_SAI, SAI_only = SAI_only)\n",
    "refine_Net = refineNet()\n",
    "depth_Net.to(device)\n",
    "refine_Net.to(device)\n",
    "depth_Net.load_state_dict(torch.load(model_folder + '/model_depth_Net.pth'))\n",
    "refine_Net.load_state_dict(torch.load(model_folder + '/model_refine_Net.pth'))\n",
    "def my_psnr(I,Iref,peakval):\n",
    "    mse = ((I-Iref)**2).mean()\n",
    "    return 10*torch.log10(peakval**2/mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Calculate Full loss across entire val dataset every epoch\n",
    "Full_loss = 0\n",
    "Full_output_loss = 0\n",
    "Full_PSNR = 0\n",
    "PSNR_all = []\n",
    "reconLF_all = np.zeros([len(ds_val),3,7,7,185,269])\n",
    "trueLF_all = np.zeros([len(ds_val),3,7,7,185,269])\n",
    "FS_all = np.zeros([len(ds_val),3,7,185,269])\n",
    "depth_all = np.zeros([len(ds_val),7,7,185,269])\n",
    "torch.cuda.empty_cache()\n",
    "for idx,data in enumerate(val_loader,0):\n",
    "    depth_Net.eval()\n",
    "    refine_Net.eval()\n",
    "\n",
    "    if SAI_only:\n",
    "        LF,est_SAI = data['LF'].to(device),data['LF'][:,:,SAI_iv,SAI_iu,:,:].to(device) # here est_SAI is the true SAI, since in SAI_only = True mode, camera captures true SAI      \n",
    "    else:\n",
    "        FS,LF,est_SAI =data['FS'].to(device),data['LF'].to(device), data['SAI'].to(device)\n",
    "        #FS,LF,est_SAI =data['FS'].to(device),data['LF'].to(device),data['LF'][:,:,SAI_iv,SAI_iu,:,:].to(device) # using true SAI as est_SAI to see How much performance can increase if SAI is estimated perfectly\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if SAI_only:\n",
    "            ray_depths = depth_Net(est_SAI) # B,v,u,H,W\n",
    "        else:\n",
    "            ray_depths = depth_Net(FS,est_SAI) # B,v,u,H,W\n",
    "        lf_shear_r = depth_rendering_pt(est_SAI[:,0,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv) # B,H,W,v,u\n",
    "        lf_shear_g = depth_rendering_pt(est_SAI[:,1,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        lf_shear_b = depth_rendering_pt(est_SAI[:,2,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        lf_shear = torch.cat([lf_shear_r.unsqueeze(5),lf_shear_g.unsqueeze(5),lf_shear_b.unsqueeze(5)],dim = 5).permute(0,5,3,4,1,2) #B,C,v,u,H,W\n",
    "        lf_denoised = refine_Net(lf_shear,ray_depths) #B,C,v,u,H,W\n",
    "\n",
    "        shear_loss = criterion(lf_shear,LF)\n",
    "        tv_loss = lam_tv * tv_loss_pt(ray_depths.permute(0,3,4,1,2))\n",
    "        depth_consistency_loss = lam_dc * depth_consistency_loss_pt(ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        output_loss = criterion(lf_denoised,LF)\n",
    "        loss = shear_loss + output_loss + tv_loss + depth_consistency_loss \n",
    "        PSNR = my_psnr(lf_denoised,LF,1)\n",
    "        \n",
    "        depth_all[idx,...]=ray_depths.cpu().numpy()\n",
    "        reconLF_all[idx,...]=lf_denoised.cpu().numpy()\n",
    "        trueLF_all[idx,...]=LF.cpu().numpy()\n",
    "        FS_all[idx,...]=FS.cpu().numpy()\n",
    "    Full_loss += loss.item()\n",
    "    Full_output_loss += output_loss.item()\n",
    "    Full_PSNR += PSNR.item()\n",
    "    PSNR_all.append(PSNR.item())\n",
    "    print('Minibatch val_loss at the end is:%.4f' %(loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "Full_loss = Full_loss/len(val_loader) # this assumes each batch has same size\n",
    "Full_output_loss = Full_output_loss/len(val_loader)\n",
    "Full_PSNR = Full_PSNR/len(val_loader)\n",
    "print('Full val_loss at the end is:%.4f' %(Full_loss))\n",
    "print('Full_PSNR at the end is:%.4f' %(Full_PSNR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "save_howmany = 30 # avoid saving too large file\n",
    "\n",
    "sio.savemat('Avoid_invcrime_Two stage model_DIBR_FS_dmin_-1_dmax_0.3_nF_7_GenMat_concat_SAI_True_disp_mult_1_detach_ray_depths_lr_3e-4_lam_tv_1e-2_lam_dc_5e-3_bs_train_1_bs_val_1_100testsample(30saved)_result.mat',{'FS_all':FS_all[:save_howmany],'depth':depth_all[:save_howmany],'trueLF_all':trueLF_all[:save_howmany],'reconLF_all':reconLF_all[:save_howmany]},do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.960785622596741"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Avg_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
