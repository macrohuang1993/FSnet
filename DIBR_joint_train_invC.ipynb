{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train viewnet and DIBR model toghther by considering the final loss only, considering inverse crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from unet_layers import *\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import FSdataset_h5,my_paired_RandomCrop,my_paired_normalize, my_paired_gamma_correction\n",
    "from visualize import show_FS,show_EPI_xu,show_EPI_yv,show_SAI\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from DIBR_modules import depth_rendering_pt,transform_ray_depths_pt,depth_consistency_loss_pt,image_derivs_pt,tv_loss_pt\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False #Setting to True may leads to faster but undeterminsitc result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 1\n",
    "bs_val = 1\n",
    "lr = 3e-4\n",
    "\n",
    "nF=7\n",
    "lfsize = [185, 269, 7, 7] #H,W,v,u\n",
    "SAI_iv = 3 #index of the SAI to be selected as All in focus image, counting from 0 \n",
    "SAI_iu = 3 #index of the SAI to be selected as All in focus image, counting from 0 \n",
    "#dimensions of Lytro light fields, H,W,nv,nu. \n",
    "#Note original Lytro LF has dimension 376X541 X 14 X 14, the paper takes only first 372/540 spatial pixel and central 8 by 8 SAI\n",
    "#which is being followed here. Here the LF is further cropped to 7 by 7 in angular dimensions.\n",
    "\n",
    "concat_SAI = True # whether concat SAI with FS along color channel for the depth estimation.(only matter when SAI_only = False)\n",
    "\n",
    "disp_mult = 1\n",
    "lam_tv = 0.01 \n",
    "lam_dc = 0.005 # 10 times larger will ensure depth fields to be consistent, not optimal yet, try reduce to 5?\n",
    "SAI_loss_weight = 2.3\n",
    "\n",
    "transform_train = T.Compose([my_paired_normalize({'FS':9000,'LF':1})]) #Since FS is not normalized in matlab and LF is normalized already to [0,1]\n",
    "transform_val = T.Compose([my_paired_normalize({'FS':9000,'LF':1})])\n",
    "\n",
    "FSdata_path = '/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5'\n",
    "LFdata_path = '/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5'\n",
    "ds_train = FSdataset_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,trainorval='train',transform = transform_train)\n",
    "ds_val =  FSdataset_h5(FSdata_path=FSdata_path,LFdata_path=LFdata_path,trainorval='val',transform = transform_val)\n",
    "log_path = 'logs/Avoid_invcrime/Two stage model(joint train)/FS_dmin_-1_dmax_0.3_nF_7/Viewnet_unet_FS2SAI_v3_tanh_DIBR_concat_SAI_True_disp_mult_1_detach_ray_depths/lr_3e-4_bs_train_1_bs_val_1_lam_tv_1e-2_lam_dc_5e-3_SAI_loss_weight_2.3'\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True, num_workers = 10,pin_memory = True)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 3,pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From DIBR_train_invC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "View_Net = unet_FS2SAI_v3(nF=nF,nu=lfsize[3],nv=lfsize[2],box_constraint = 'tanh')\n",
    "depth_Net = depth_network_pt(nF,lfsize,disp_mult,concat_SAI = concat_SAI)\n",
    "refine_Net = refineNet()\n",
    "\n",
    "View_Net.to(device)\n",
    "depth_Net.to(device)\n",
    "refine_Net.to(device)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "params =list(View_Net.parameters()) + list(depth_Net.parameters()) + list(refine_Net.parameters())\n",
    "optimizer=optim.Adam(params,lr=lr)\n",
    "\n",
    "def my_psnr(I,Iref,peakval):\n",
    "    mse = ((I-Iref)**2).mean()\n",
    "    return 10*torch.log10(peakval**2/mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=0\n",
    "for epoch in range(50):    \n",
    "    #scheduler.step()\n",
    "    print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        View_Net.train()\n",
    "        depth_Net.train()\n",
    "        refine_Net.train()\n",
    "        \n",
    "        FS,LF =data['FS'].to(device),data['LF'].to(device)\n",
    "        #FS,LF,est_SAI =data['FS'].to(device),data['LF'].to(device),data['LF'][:,:,SAI_iv,SAI_iu,:,:].to(device) # using true SAI as est_SAI to see How much performance can increase if SAI is estimated perfectly\n",
    "        est_SAI=View_Net(FS)\n",
    "        trueSAI = LF[:,:,SAI_iv,SAI_iu,:,:] #B,C,H,W\n",
    "\n",
    "        \n",
    "        ray_depths = depth_Net(FS,est_SAI) # B,v,u,H,W\n",
    "        \n",
    "        lf_shear_r = depth_rendering_pt(est_SAI[:,0,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv) # B,H,W,v,u\n",
    "        lf_shear_g = depth_rendering_pt(est_SAI[:,1,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        lf_shear_b = depth_rendering_pt(est_SAI[:,2,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        lf_shear = torch.cat([lf_shear_r.unsqueeze(5),lf_shear_g.unsqueeze(5),lf_shear_b.unsqueeze(5)],dim = 5).permute(0,5,3,4,1,2) #B,C,v,u,H,W\n",
    "        lf_denoised = refine_Net(lf_shear,ray_depths.detach()) #B,C,v,u,H,W\n",
    "\n",
    "        shear_loss = criterion(lf_shear,LF)\n",
    "        tv_loss = lam_tv * tv_loss_pt(ray_depths.permute(0,3,4,1,2))\n",
    "        depth_consistency_loss = lam_dc * depth_consistency_loss_pt(ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "        output_loss = criterion(lf_denoised,LF)        \n",
    "        with torch.no_grad():\n",
    "            SAI_loss=criterion(est_SAI,trueSAI)\n",
    "        loss = shear_loss + output_loss + tv_loss + depth_consistency_loss + SAI_loss_weight * SAI_loss\n",
    "        print('Train Loss is %3f' %(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        if step % 10 == 0:\n",
    "            writer.add_scalar('shear_loss', shear_loss.item(), step)   \n",
    "            writer.add_scalar('tv_loss', tv_loss.item(), step)   \n",
    "            writer.add_scalar('depth_consistency_loss', depth_consistency_loss.item(), step)   \n",
    "            writer.add_scalar('output_loss', output_loss.item(), step)   \n",
    "            writer.add_scalar('SAI_loss', SAI_loss.item(), step) \n",
    "            writer.add_scalar('loss', loss.item(), step)      \n",
    "        if step % 400 == 0:\n",
    "            print('Train visualization')\n",
    "            est_SAI_grid = show_SAI(est_SAI.detach().cpu(), isshow = False) \n",
    "            FS_grid = show_FS(FS, isshow = False)\n",
    "            LambertLF_SAI_grid = show_SAI(lf_shear.detach().cpu(),[(0,0),(3,3)], isshow = False)\n",
    "            LambertLF_EPI_xu_grid = show_EPI_xu(lf_shear.detach().cpu(),[(100,0),(150,3)],isshow = False)\n",
    "            reconLF_SAI_grid = show_SAI(lf_denoised.detach().cpu(),[(0,0),(3,3)], isshow = False)\n",
    "            reconLF_EPI_xu_grid = show_EPI_xu(lf_denoised.detach().cpu(),[(100,0),(150,3)],isshow = False)\n",
    "            SAI_grid = show_SAI(LF.detach().cpu(),[(0,0),(3,3)], isshow = False) \n",
    "            EPI_xu_grid = show_EPI_xu(LF.detach().cpu(),[(100,0),(150,3)], isshow = False)  \n",
    "            \n",
    "            \n",
    "            B,v,u,H,W = ray_depths.shape\n",
    "            writer.add_image('Training ray_depths', ray_depths.permute(0,1,3,2,4).reshape(B*v*H,u*W), step)\n",
    "            writer.add_image('Training est SAI', est_SAI_grid, step)\n",
    "            writer.add_image('Training FS', FS_grid, step)\n",
    "            writer.add_image('Training LambertLF SAI [0,0], [3,3]', LambertLF_SAI_grid, step)\n",
    "            writer.add_image('Training LambertLF EPI [100,0], [150,3]', LambertLF_EPI_xu_grid, step)\n",
    "            writer.add_image('Training reconLF SAI [0,0], [3,3]', reconLF_SAI_grid, step)\n",
    "            writer.add_image('Training reconLF EPI [100,0], [150,3]', reconLF_EPI_xu_grid, step)\n",
    "            writer.add_image('Training trueLF SAI [0,0], [3,3]', SAI_grid, step)\n",
    "            writer.add_image('Training trueLF EPI [100,0], [150,3]', EPI_xu_grid, step)  \n",
    "        \n",
    "        step = step + 1 \n",
    "        \n",
    "    #Calculate Full loss across entire val dataset every epoch\n",
    "    Full_loss = 0\n",
    "    Full_output_loss = 0\n",
    "    Full_PSNR = 0\n",
    "    Full_SAI_loss = 0\n",
    "    torch.cuda.empty_cache()\n",
    "    for idx,data in enumerate(val_loader,0):\n",
    "        View_Net.eval()\n",
    "        depth_Net.eval()\n",
    "        refine_Net.eval()\n",
    "        \n",
    "        FS,LF =data['FS'].to(device),data['LF'].to(device)\n",
    "        #FS,LF,est_SAI =data['FS'].to(device),data['LF'].to(device),data['LF'][:,:,SAI_iv,SAI_iu,:,:].to(device) # using true SAI as est_SAI to see How much performance can increase if SAI is estimated perfectly\n",
    "        est_SAI=View_Net(FS)\n",
    "        trueSAI = LF[:,:,SAI_iv,SAI_iu,:,:] #B,C,H,W\n",
    "        with torch.no_grad():\n",
    "            ray_depths = depth_Net(FS,est_SAI) # B,v,u,H,W\n",
    "            lf_shear_r = depth_rendering_pt(est_SAI[:,0,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv) # B,H,W,v,u\n",
    "            lf_shear_g = depth_rendering_pt(est_SAI[:,1,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "            lf_shear_b = depth_rendering_pt(est_SAI[:,2,:,:],ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "            lf_shear = torch.cat([lf_shear_r.unsqueeze(5),lf_shear_g.unsqueeze(5),lf_shear_b.unsqueeze(5)],dim = 5).permute(0,5,3,4,1,2) #B,C,v,u,H,W\n",
    "            lf_denoised = refine_Net(lf_shear,ray_depths) #B,C,v,u,H,W\n",
    "\n",
    "            shear_loss = criterion(lf_shear,LF)\n",
    "            tv_loss = lam_tv * tv_loss_pt(ray_depths.permute(0,3,4,1,2))\n",
    "            depth_consistency_loss = lam_dc * depth_consistency_loss_pt(ray_depths.permute(0,3,4,1,2),lfsize,SAI_iu,SAI_iv)\n",
    "            output_loss = criterion(lf_denoised,LF)\n",
    "            SAI_loss=criterion(est_SAI,trueSAI)\n",
    "            loss = shear_loss + output_loss + tv_loss + depth_consistency_loss + SAI_loss_weight * SAI_loss\n",
    "            PSNR = my_psnr(lf_denoised,LF,1)\n",
    "            \n",
    "        Full_loss += loss.item()\n",
    "        Full_output_loss += output_loss.item()\n",
    "        Full_PSNR += PSNR.item()\n",
    "        Full_SAI_loss += SAI_loss.item()\n",
    "        print('Minibatch val_loss at the end of epoch %d is:%.4f' %(epoch, loss.item()))\n",
    "        \n",
    "        \n",
    "        \n",
    "    Full_loss = Full_loss/len(val_loader) # this assumes each batch has same size\n",
    "    Full_output_loss = Full_output_loss/len(val_loader)\n",
    "    Full_PSNR = Full_PSNR/len(val_loader)\n",
    "    Full_SAI_loss = Full_SAI_loss/len(val_loader)\n",
    "    print('Full val_loss at the end of epoch %d is:%.4f' %(epoch,Full_loss))\n",
    "    print('Full_PSNR at the end of epoch %d is:%.4f' %(epoch,Full_PSNR))\n",
    "    writer.add_scalar('Full val loss', Full_loss, epoch)    \n",
    "    writer.add_scalar('Full Val LF output loss', Full_output_loss, epoch) \n",
    "    writer.add_scalar('Full Val PSNR',Full_PSNR, epoch)\n",
    "    writer.add_scalar('Full Val SAI loss',Full_SAI_loss, epoch)\n",
    "    torch.save(View_Net.state_dict(), os.path.join(log_path, 'model_View_Net.pth'))\n",
    "    torch.save(refine_Net.state_dict(), os.path.join(log_path, 'model_refine_Net.pth'))\n",
    "    torch.save(depth_Net.state_dict(), os.path.join(log_path, 'model_depth_Net.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
