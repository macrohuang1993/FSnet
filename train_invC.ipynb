{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Unet for direct LF reconstruction from FS, considering inverse crime.\n",
    "Use train.ipynb instead for version without considering inverse crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from unet_layers import *\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import FSdataset_h5,my_paired_RandomCrop,my_paired_normalize, my_paired_gamma_correction\n",
    "from visualize import show_FS,show_EPI_xu,show_EPI_yv,show_SAI\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False #Setting to True may leads to faster but undeterminsitc result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 2\n",
    "bs_val = 5\n",
    "lr = 5e-4\n",
    "\n",
    "nF=7\n",
    "lfsize = [185, 269, 7, 7] #H,W,v,u\n",
    "#dimensions of Lytro light fields, H,W,nv,nu. \n",
    "#Note original Lytro LF has dimension 376X541 X 14 X 14, the paper takes only first 372/540 spatial pixel and central 8 by 8 SAI\n",
    "#which is being followed here\n",
    "\n",
    "transform_train = T.Compose([my_paired_normalize({'FS':9000,'LF':1})]) #Since FS is not normalized in matlab and LF is normalized already to [0,1]\n",
    "transform_val = T.Compose([my_paired_normalize({'FS':9000,'LF':1})])\n",
    "\n",
    "\n",
    "ds_train = FSdataset_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',\\\n",
    "                        LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='train',transform = transform_train)\n",
    "ds_val =  FSdataset_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',\\\n",
    "                       LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='val',transform = transform_val)\n",
    "\n",
    "log_path = 'logs/Avoid_invcrime/FS_dmin_-1_dmax_0.3_nF_7/unet_FS2LF_v3_tanh/lr_5e-4_bs_train_2_bs_val_5'\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True, num_workers = 10,pin_memory = True)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 5,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "net = unet_FS2LF_v3(nF=nF,nu=lfsize[3],nv=lfsize[2],box_constraint = 'tanh')\n",
    "net.to(device)\n",
    "criterion = nn.L1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer=optim.Adam(net.parameters(),lr=lr)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[3,6,10,20], gamma=0.5)\n",
    "\n",
    "def my_psnr(I,Iref,peakval):\n",
    "    mse = ((I-Iref)**2).mean()\n",
    "    return 10*torch.log10(peakval**2/mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 =time.time()\n",
    "step=0\n",
    "for epoch in range(100):\n",
    "#    scheduler.step()\n",
    "    print(\"Current epoch number%d\" %epoch) \n",
    "    for idx,data in enumerate(train_loader,0):\n",
    "        net.train()\n",
    "        FS,LF=data['FS'].to(device),data['LF'].to(device) # 2019 4 16: check loaded FS, LF dimension and make sure they are compatible with network struture here\n",
    "        reconLF=net(FS)\n",
    "        loss=criterion(reconLF,LF)\n",
    "        print('Train Loss is %3f' %(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            writer.add_scalar('output_loss', loss.item(), step)    \n",
    "        if step % 1000 == 0:\n",
    "            \n",
    "            print('Train visualization')\n",
    "            reconSAI_grid = show_SAI(reconLF.detach().cpu(),[(0,0),(3,3)], isshow = False)\n",
    "            reconEPI_xu_grid = show_EPI_xu(reconLF.detach().cpu(),[(100,0),(150,3)],isshow = False)\n",
    "            SAI_grid = show_SAI(LF.detach().cpu(),[(0,0),(3,3)], isshow = False) \n",
    "            EPI_xu_grid = show_EPI_xu(LF.detach().cpu(),[(100,0),(150,3)], isshow = False)    \n",
    "            FS_grid = show_FS(FS, isshow = False)\n",
    "            writer.add_image('Training reconLF SAI [0,0], [3,3]', reconSAI_grid, step)\n",
    "            writer.add_image('Training reconLF EPI [100,0], [150,3]', reconEPI_xu_grid, step)\n",
    "            writer.add_image('Training trueLF SAI [0,0], [3,3]', SAI_grid, step)\n",
    "            writer.add_image('Training trueLF EPI [100,0], [150,3]', EPI_xu_grid, step)  \n",
    "            writer.add_image('Training FS', FS_grid, step)  \n",
    "        step = step + 1 \n",
    "\n",
    "  \n",
    "    #Calculate Full loss across entire val dataset every epoch\n",
    "    Full_output_loss = 0\n",
    "    Full_PSNR = 0\n",
    "    for idx,data in enumerate(val_loader,0):\n",
    "        net.eval()\n",
    "        FS,LF=data['FS'].to(device),data['LF'].to(device) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            reconLF=net(FS)\n",
    "            loss=criterion(reconLF,LF)\n",
    "            PSNR = my_psnr(reconLF,LF,1) ##Note if batch size is not 1, then final Full_PSNR is not exactly the average PSNR of each sample LF, but the average \n",
    "                                        #PSNR of considering the batch LF as a meta-image, as one single sample, this will be slightly different.\n",
    "        #visualize first batch val sample\n",
    "        if idx == 0:\n",
    "            print('Validation visualization')\n",
    "            reconSAI_grid = show_SAI(reconLF.detach().cpu(),[(0,0),(3,3)], isshow = False)\n",
    "            reconEPI_xu_grid = show_EPI_xu(reconLF.detach().cpu(),[(100,0),(150,3)],isshow = False)\n",
    "            SAI_grid = show_SAI(LF.detach().cpu(),[(0,0),(3,3)], isshow = False) \n",
    "            EPI_xu_grid = show_EPI_xu(LF.detach().cpu(),[(100,0),(150,3)], isshow = False)      \n",
    "            FS_grid = show_FS(FS.cpu(), isshow = False)\n",
    "            writer.add_image('Val reconLF SAI [0,0], [3,3]', reconSAI_grid, epoch)\n",
    "            writer.add_image('Val reconLF EPI [100,0], [150,3]', reconEPI_xu_grid, epoch)\n",
    "            writer.add_image('Val trueLF SAI [0,0], [3,3]', SAI_grid, epoch)\n",
    "            writer.add_image('Val trueLF EPI [100,0], [150,3]', EPI_xu_grid, epoch)\n",
    "            writer.add_image('Val FS', FS_grid, epoch)  \n",
    "        print('Minibatch val_loss at the end of epoch %d is:%.4f' %(epoch, loss.item()))\n",
    "        print('Minibatch PSNR at the end of epoch %d is:%.4f' %(epoch, PSNR.item()))\n",
    "        Full_output_loss += loss.item()\n",
    "        Full_PSNR += PSNR.item()\n",
    "                           \n",
    "    Full_output_loss = Full_output_loss/len(val_loader)# this assumes each batch has same size\n",
    "    Full_PSNR = Full_PSNR/len(val_loader)\n",
    "    print('Full_output_loss at the end of epoch %d is:%.4f' %(epoch,Full_output_loss))\n",
    "    print('Full_PSNR at the end of epoch %d is:%.4f' %(epoch,Full_PSNR))\n",
    "    writer.add_scalar('Full Val LF output loss',Full_output_loss, epoch)\n",
    "    writer.add_scalar('Full Val PSNR',Full_PSNR, epoch)\n",
    "    torch.save(net.state_dict(), os.path.join(log_path, 'model.pth'))\n",
    "    #torch.cuda.empty_cache()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
