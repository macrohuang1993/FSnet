{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Code and timing benchmark code for train_invC.ipynb\n",
    "Compares the timing performance of direct regression CNN and (possibly) loaded matlab EP recon results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from unet_layers import *\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import FSdataset_h5,my_paired_RandomCrop,my_paired_normalize, my_paired_gamma_correction\n",
    "from visualize import show_FS,show_EPI_xu,show_EPI_yv,show_SAI\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from scipy.io import loadmat\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "np.random.seed(100);\n",
    "torch.manual_seed(100);\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False #Setting to True may leads to faster but undeterminsitc result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bs_train = 2\n",
    "bs_val = 1 # Use 1 is recommended for properly calculating average PSNR\n",
    "nF=7\n",
    "lfsize = [185, 269, 7, 7] #H,W,v,u\n",
    "#dimensions of Lytro light fields, H,W,nv,nu. \n",
    "#Note original Lytro LF has dimension 376X541 X 14 X 14, the paper takes only first 372/540 spatial pixel and central 8 by 8 SAI\n",
    "#which is being followed here\n",
    "\n",
    "#transform_train = T.Compose([my_paired_normalize({'FS':9000,'LF':1})]) #Since FS is not normalized in matlab and LF is normalized already to [0,1]\n",
    "transform_val = T.Compose([my_paired_normalize({'FS':9000,'LF':1})])\n",
    "\n",
    "#ds_train = FSdataset_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='train',transform = transform_train)\n",
    "ds_val =  FSdataset_h5(FSdata_path='/home/zyhuang/EVO970Plus/FS_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',LFdata_path='/home/zyhuang/EVO970Plus/LF_dataset/FS_dmin_-1_dmax_0.3_nF_7_inverseCrime.h5',trainorval='val',transform = transform_val)\n",
    "\n",
    "path = 'logs/Avoid_invcrime/Direct regression/FS_dmin_-1_dmax_0.3_nF_7_GenMat/unet_FS2LF_v3_tanh/lr_5e-4_bs_train_2_bs_val_5/model.pth'\n",
    "\n",
    "#train_loader=DataLoader(ds_train, batch_size=bs_train,shuffle=True, num_workers = 10,pin_memory = True)\n",
    "val_loader=DataLoader(ds_val, batch_size=bs_val,shuffle=False, num_workers = 5,pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = unet_FS2LF_v3(nF=nF,nu=lfsize[3],nv=lfsize[2],box_constraint = 'tanh')\n",
    "net.load_state_dict(torch.load(path))\n",
    "criterion = nn.L1Loss()\n",
    "#criterion = nn.MSELoss()\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[3,6,10,20], gamma=0.5)\n",
    "\n",
    "def my_psnr(I,Iref,peakval):\n",
    "    mse = ((I-Iref)**2).mean()\n",
    "    return 10*torch.log10(peakval**2/mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0\n",
    "#Calculate Full loss across entire val dataset every epoch\n",
    "Full_output_loss = 0\n",
    "Full_PSNR = 0\n",
    "device = torch.device(\"cpu\") #switch between cuda and cpu\n",
    "net.to(device)\n",
    "reconLF_all = np.zeros([len(ds_val),3,7,7,185,269])\n",
    "trueLF_all = np.zeros([len(ds_val),3,7,7,185,269])\n",
    "for idx,data in enumerate(val_loader,0):\n",
    "    net.eval()\n",
    "    t1 =time.time()\n",
    "    FS,LF=data['FS'].to(device),data['LF'].to(device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconLF=net(FS)\n",
    "        loss=criterion(reconLF,LF)\n",
    "        PSNR = my_psnr(reconLF,LF,1)\n",
    "        #reconLF_all[idx,...]=reconLF.cpu().numpy()\n",
    "        #trueLF_all[idx,...]=LF.cpu().numpy()\n",
    "    t2 = time.time()\n",
    "    dt += (time.time() -t1)\n",
    "    print('Minibatch val_loss is:%.4f' %(loss.item()))\n",
    "    print('Minibatch PSNR is:%.4f' %(PSNR.item()))\n",
    "    Full_output_loss += loss.item()\n",
    "    Full_PSNR += PSNR.item()\n",
    "\n",
    "Full_output_loss = Full_output_loss/len(val_loader)# this assumes each batch has same size\n",
    "Full_PSNR = Full_PSNR/len(val_loader)\n",
    "Average_reconTime = dt/len(val_loader)\n",
    "print('Average_reconTime is:%.4f s' %(Average_reconTime)) # use bs_val = 1! for timing\n",
    "print('Full_output_loss is:%.4f' %(Full_output_loss))\n",
    "print('Full_PSNR is:%.4f' %(Full_PSNR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "save_howmany = 50 # avoid saving too large file\n",
    "sio.savemat('Direct_regression_unet_FS2LF_v3_tanh_lr_5e-4_bs_train_2_bs_val_5_100testsample_result.mat',{'trueLF_all':trueLF_all[:save_howmany],'reconLF_all':reconLF_all[:save_howmany]},do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds_val[0]['FS'][:,1,...].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For generating timing comparision plot\n",
    "The matlab EP recon timing need to be generated before hand by running iter_recon_EP.m using proper choice of reg parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_PSNRvsTime = loadmat('/media/WD/LF_recon/Result_FSNet_baseline/Val5_PSNRvsTime.mat')['PSNRvsTime']\n",
    "dt_gpu = 0.0178 # Result from above \n",
    "dt_cpu = 0.24 # Result from above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_gpu=np.arange(0,EP_PSNRvsTime[:,0].max(),dt_gpu)\n",
    "t_cpu=np.arange(0,EP_PSNRvsTime[:,0].max(),dt_cpu)\n",
    "PSNR_CNN_gpu = np.zeros_like(t_gpu)\n",
    "PSNR_CNN_cpu = np.zeros_like(t_cpu)\n",
    "PSNR_CNN_gpu[1:] = 37.955\n",
    "PSNR_CNN_cpu[1:] = 37.955\n",
    "\n",
    "plt.scatter(EP_PSNRvsTime[:,0],EP_PSNRvsTime[:,1])\n",
    "plt.title('ReconLF average PSNR (first 5 test samples)')\n",
    "plt.ylabel('PSNR (dB)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "\n",
    "plt.plot()\n",
    "plt.plot(t_gpu,PSNR_CNN_gpu)\n",
    "plt.plot(t_cpu,PSNR_CNN_cpu)\n",
    "plt.ylim([32,40])\n",
    "plt.legend(['Unet_GPU ({:.4f} s)'.format(dt_gpu),'Unet_CPU ({:.4f} s)'.format(dt_cpu),'EP_recon_pcg'])\n",
    "#plt.savefig('Timing compare.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Animation of the LF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Camera moving grid\n",
    "idx_v=[0,0,0,0,0,0,0,1,2,3,4,5,6,6,6,6,6,6,6,5,4,3,2,1,0]\n",
    "idx_u=[0,1,2,3,4,5,6,6,6,6,6,6,6,5,4,3,2,1,0,0,0,0,0,0,0]\n",
    "\n",
    "filenames_LFrecon=[]\n",
    "filenames_trueLF=[]\n",
    "for i in range(len(idx_u)):\n",
    "    fig = plt.imshow(reconLF[0,:,idx_v[i],idx_u[i],:,:].cpu().detach().permute([1,2,0]))\n",
    "    filename = '{:d}_{:d}_recon.png'.format(idx_v[i],idx_u[i])\n",
    "    plt.savefig(filename)\n",
    "    filenames_LFrecon.append(filename)\n",
    "    \n",
    "for i in range(len(idx_u)):\n",
    "    fig = plt.imshow(LF[0,:,idx_v[i],idx_u[i],:,:].cpu().detach().permute([1,2,0]))\n",
    "    filename = '{:d}_{:d}_true.png'.format(idx_v[i],idx_u[i])\n",
    "    plt.savefig(filename)\n",
    "    filenames_trueLF.append(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for filename in filenames_LFrecon:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('LFrecon.gif', images)\n",
    "\n",
    "images = []\n",
    "for filename in filenames_trueLF:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('trueLF.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
